{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GAMMA = 0.999\n",
    "K = 4 # each state is a block of 4 states, the agent selects action every k states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment Handler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentHandler:\n",
    "    def __init__(self, env_name = \"Pong-v0\"):\n",
    "        self.env = gym.make(env_name)\n",
    "        \n",
    "    def _preprocess_image(self,image):\n",
    "        gray = skimage.color.rgb2gray(image)\n",
    "        downscale = skimage.transform.resize(gray, (110, 84), anti_aliasing=False)\n",
    "        crop = downscale[18:102]\n",
    "        normalize = crop/255.0\n",
    "        return normalize\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        \n",
    "    def get_next_k_states(self, k, action):\n",
    "        \"\"\"returns a tensor image with k channels shape = (k,h,w)\"\"\"\n",
    "        images = []\n",
    "        rewards = []\n",
    "        done = []\n",
    "        for i in range(k):\n",
    "            image,reward,d,_ = self.env.step(action if i == 0 else 0)\n",
    "            images.append(torch.tensor(self._preprocess_image(image), dtype = torch.float32).unsqueeze(0))\n",
    "            rewards.append(reward)\n",
    "            done.append(d)\n",
    "        self.rewards = rewards\n",
    "        self.dones = done\n",
    "        return torch.cat(images).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    def sample_action_space(self):\n",
    "        return self.env.action_space.sample()\n",
    "        \n",
    "    def get_reward(self):\n",
    "        return sum(self.rewards)\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "    \n",
    "    @property\n",
    "    def done(self):\n",
    "        for d in self.dones:\n",
    "            if d:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return self.env.action_space\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experience Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience:\n",
    "    def __init__(self, state, action, reward, next_state):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.next_state = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is smart! Overwriting previous array values is more efficient than shifting everything backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = []\n",
    "        self.cache_pointer = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cache)\n",
    "    \n",
    "    def push(self, experience):\n",
    "        if len(self.cache) < self.capacity:\n",
    "            self.cache.append(experience)\n",
    "        else:\n",
    "            self.cache[self.cache_pointer] = experience\n",
    "        self.cache_pointer = (self.cache_pointer + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.cache, batch_size)\n",
    "    '''\n",
    "    def get_last_n_frames(self, n = 4):\n",
    "        next_index = self.cache_pointer + len(self.cache)\n",
    "        last_n_frames = [torch.tensor(exp.state, dtype = torch.float32).unsqueeze(0) for exp in (self.cache * 2)[next_index - n: next_index]]\n",
    "        return torch.cat(last_n_frames).unsqueeze(0).to(DEVICE)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, action_space_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, 8, stride = 4)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 4, stride = 2)\n",
    "        self.fc1 = nn.Linear(2592, 256)\n",
    "        self.fc2 = nn.Linear(256, action_space_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"Input should be 4x84x84\"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Epsilon Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon(start = 1, stop = 0.1, num = 1_000_000):\n",
    "    epsilons = np.linspace(start, stop, num)\n",
    "    for i in epsilons:\n",
    "        yield i\n",
    "    while True:\n",
    "        yield stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_handler = EnvironmentHandler()\n",
    "env_handler.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(4, 16, kernel_size=(8, 8), stride=(4, 4))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (fc1): Linear(in_features=2592, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ReplayMemory(1500)\n",
    "dqn = DQN(3)\n",
    "dqn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"dqn_at_ep1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(dqn.parameters(), lr=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90a200e69824f2cb691c43e7583d6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-53eaec2c4b1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mbatch_current_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom_minibatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_current_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-5e36039be74a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;34m\"\"\"Input should be 4x84x84\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 5000\n",
    "batch_size = 32\n",
    "epsilon_generator = iter(epsilon(0.8,0.05,500000))\n",
    "\n",
    "#initialize current_state\n",
    "current_state = env_handler.get_next_k_states(K, 0)\n",
    "\n",
    "for episode in tqdm(range(1000,episodes)):\n",
    "    done = False\n",
    "    env_handler.reset()\n",
    "    while not done:\n",
    "        if random.uniform(0,1) < next(epsilon_generator):\n",
    "            #action = env_handler.action_space.sample()\n",
    "            action = random.sample([1,2,3],1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                # action = dqn(current_state).argmax().item()\n",
    "                action = dqn(current_state).argmax().item() + 1 # choose betwen 1,2,3\n",
    "        next_state = env_handler.get_next_k_states(K, action)\n",
    "        reward = env_handler.get_reward()    \n",
    "        done = env_handler.done\n",
    "        memory.push(Experience(current_state, action, reward, next_state))\n",
    "        \n",
    "        if len(memory) < batch_size:\n",
    "            break\n",
    "        \n",
    "        random_minibatch = memory.sample(batch_size)\n",
    "        \n",
    "        y = torch.tensor([exp.reward for exp in random_minibatch], device = DEVICE)\n",
    "        if not done:\n",
    "            batch_next_state = torch.cat([exp.next_state for exp in random_minibatch])\n",
    "            y = y + GAMMA * dqn(batch_next_state).max(dim = 1)[0]\n",
    "        \n",
    "        batch_current_state = torch.cat([exp.state for exp in random_minibatch])\n",
    "        \n",
    "        l = ((y - dqn(batch_current_state).max(dim = 1)[0])**2).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #update current state for next cycle\n",
    "        current_state = next_state\n",
    "        \n",
    "        if episode%10 == 0:\n",
    "            env_handler.env.render()\n",
    "    if episode%100 == 0:\n",
    "        torch.save(dqn.state_dict(), f\"./dqn_at_ep{episode}\")\n",
    "env_handler.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981918981918982"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(epsilon_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323, -0.9677,  0.0323,\n",
       "         0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,\n",
       "         0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,\n",
       "         0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323,  0.0323],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.max(dim = 1)[0] + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Experience at 0x2c7bd8a0bc8>,\n",
       " <__main__.Experience at 0x2c7bd8a0348>,\n",
       " <__main__.Experience at 0x2c7bd8a2688>]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6], device='cuda:0')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2], device = DEVICE) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999972999973"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = env.render(mode = \"rgb_array\")\n",
    "action = env.action_space.sample()\n",
    "next_state, reward, _, _ = env.step(action)\n",
    "for _ in range(4):\n",
    "    memory.push(Experience(current_state, action, reward, next_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    foo =dqn(memory.get_last_n_frames())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.argmax().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = env.render(mode = \"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(env.action_space.sample())\n",
    "foo = env.render(mode = \"rgb_array\")\n",
    "bar = rgb2gray(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c7a9177148>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayMemory(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    current_state = env.render(mode = \"rgb_array\")\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.push(Experience(current_state, action, reward, next_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 84, 84])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_last_n_frames().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<AtariEnv<Pong-v0>>>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo (env):\n",
    "    env = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<AtariEnv<Pong-v0>>>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(4, 16, kernel_size=(8, 8), stride=(4, 4))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (fc1): Linear(in_features=2592, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = DQN(6)\n",
    "dqn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0495, -0.0457, -0.0279,  0.0414,  0.0378, -0.0152]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn(memory.get_last_n_frames())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple(\"Experience\", [\"state\", \"action\", \"reward\", \"next_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, memory_capacity):\n",
    "        self.memory = []\n",
    "        self.capacity = memory_capacity\n",
    "        # the pointer should always point to the next position\n",
    "        self.pointer = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def append(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.pointer] = experience\n",
    "        self.pointer = (self.pointer + 1) % self.capacity\n",
    "            \n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateCache(ReplayMemory):\n",
    "    def __init__(self, capacity = 10):\n",
    "        super().__init__(capacity)\n",
    "    \n",
    "    def get_average_states(self):\n",
    "        if len(self.memory) == 1:\n",
    "            return self.memory[0]\n",
    "        else:\n",
    "            return torch.stack(self.memory).mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Sequential(\n",
    "                        nn.Linear(128,64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64,32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, 16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16,6))\n",
    "    def forward(self, x):\n",
    "        x = x / 255.0 #normalize input\n",
    "        x = self.weights(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon(start = 1, stop = 0.1, num = 1000000):\n",
    "    epsilons = np.linspace(start, stop, num)\n",
    "    for i in epsilons:\n",
    "        yield i\n",
    "    while True:\n",
    "        yield stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-ram-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982907ed2cb640f4b67c06a51ed15398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-c791caad6ff4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_avg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "replay_memory = ReplayMemory(10000)\n",
    "dqn = DQN()\n",
    "dqn.to(DEVICE)\n",
    "episodes = 5000\n",
    "epsilon_generator = iter(epsilon())\n",
    "bs = 100\n",
    "gamma = 0.999\n",
    "optimizer = torch.optim.RMSprop(dqn.parameters())\n",
    "\n",
    "env.reset()\n",
    "current_state, reward, done, _ = env.step(env.action_space.sample())\n",
    "current_state = torch.tensor(current_state, dtype = torch.float32, device = DEVICE)\n",
    "for episode in tqdm(range(episodes)):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        state_cache = StateCache(5)\n",
    "        state_cache.append(current_state)\n",
    "        current_state = state_cache.get_average_states()\n",
    "        \n",
    "        if random.uniform(0,1) < next(epsilon_generator):\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                action = dqn(current_state).argmax().item()\n",
    "                \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = torch.tensor(next_state, dtype = torch.float32, device = DEVICE)\n",
    "        \n",
    "        state_cache.append(next_state)\n",
    "        next_state = state_cache.get_average_states()\n",
    "        \n",
    "        replay_memory.append(Experience(current_state, action, reward, next_state))\n",
    "        \n",
    "        if len(replay_memory) < bs:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        random_minibatch = replay_memory.sample(bs)\n",
    "        y = torch.tensor([experience.reward for experience in random_minibatch], device = DEVICE)\n",
    "        if not done:\n",
    "            batch_next_state = torch.stack([exp.next_state for exp in random_minibatch])\n",
    "            y += gamma * dqn(batch_next_state).max(dim = 1)[0]\n",
    "        \n",
    "\n",
    "        batch_current_state = torch.stack([experience.state for experience in random_minibatch])\n",
    "        l = ((y - dqn(batch_current_state).max(dim = 1)[0])**2).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_state = next_state\n",
    "        \n",
    "        env.render()\n",
    "        \n",
    "    if episode%100 == 0:\n",
    "        torch.save(dqn.state_dict(), f\"./dqn_at_ep{episode}\")\n",
    "env.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7028611028611029"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(epsilon_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6477a77aea6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'foo' is not defined"
     ]
    }
   ],
   "source": [
    "current_state = torch.tensor(foo[0], dtype = torch.float32, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (weights): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = DQN()\n",
    "dqn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([71.5000, 71.5000], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([current_state, current_state]).mean(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[71.6562],\n",
       "        [71.6562]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([current_state, current_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-ram-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127,  60, 165,  12,  20, 164, 119,  31,  88, 226,  47, 210,  13,\n",
       "        28, 171, 211, 108, 253,   7, 246,  11, 149, 135,  62,  83,  66,\n",
       "        75, 113,  67, 243,  64, 172, 253, 198,   9, 183, 210,  73, 165,\n",
       "        69,   7, 105, 107,  53,  50, 159, 243, 219,  14, 201, 236,  51,\n",
       "        98,  44,  91, 213, 159, 247, 214,  50,   7,  11,  96,  76, 142,\n",
       "       233,  83,  90, 224,  48, 155,  49, 137, 123, 231,  72,  84, 210,\n",
       "       145, 101, 239,  67, 130,  63,  19, 235, 250, 231, 168,  65,  96,\n",
       "        83,  12, 198,  72, 193, 114, 162,  63, 251, 105, 111,  74,  34,\n",
       "       203, 252,  74,  29, 122,  88, 230, 139,  49,  72,  88, 172, 129,\n",
       "       185,  20, 104, 210, 162, 232,  44, 172,  37,  87, 129], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    output, reward, done, _ = env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([192,   0,  64,   0, 110,  38,   0,   7,  23,  15,   0,  63,  14,\n",
       "         21,   0,  63, 255,   0,   0,   2,   0,  52,   0,  24, 128,  32,\n",
       "          1,  86, 247,  86, 247,  86, 247, 134, 243, 245, 243, 240, 240,\n",
       "        242, 242,  32,  32,  64,  64,  64, 188,  65, 189, 205,  52,  38,\n",
       "         37,  37,  51,   0, 255,   0, 255, 109,  38,  37,  37, 192, 192,\n",
       "        192, 192, 192, 192, 207, 247, 202, 247, 212, 247, 202, 247,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 180,  85,  54, 236, 242, 121, 240], dtype=uint8),\n",
       " 0.0,\n",
       " True,\n",
       " {'ale.lives': 0, 'TimeLimit.truncated': False})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

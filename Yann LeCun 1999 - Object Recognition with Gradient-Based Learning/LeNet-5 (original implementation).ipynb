{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"LeNet5_architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, we use the paper's original architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(root = \"../data\", download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrainingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, mean, std):\n",
    "        super().__init__()\n",
    "        train = data.reshape((-1,1,28,28))\n",
    "        flat = train.flatten().to(torch.float32)\n",
    "\n",
    "        self.train = ((train - mean)/ std).to(device)\n",
    "        self.label = targets.to(torch.long).to(device)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.train[i], self.label[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_datasets():\n",
    "    #we have to use the training mean on the test set\n",
    "    train = mnist.data[:50000].reshape((-1,1,28,28))\n",
    "    flat = train.flatten().to(torch.float32)\n",
    "    mean = flat.mean()\n",
    "    std = flat.std()\n",
    "    \n",
    "    return MNISTTrainingDataset(mnist.data[:50000], mnist.targets[:50000], mean,std),\\\n",
    "        MNISTTrainingDataset(mnist.data[50000:], mnist.targets[50000:], mean, std)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = train_test_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size = bs, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size = bs, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSampling(nn.Module):\n",
    "    def __init__(self, kernel_size, stride = None):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(1, requires_grad = True, dtype = torch.float32, device = device))\n",
    "        self.b = nn.Parameter(torch.tensor(1, requires_grad = True, dtype = torch.float32, device = device))\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride if stride else kernel_size\n",
    "            \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            channels = x.shape[1]\n",
    "\n",
    "        kernel = torch.ones(channels, channels, self.kernel_size, self.kernel_size).type(torch.float32).to(device)\n",
    "        \n",
    "        x = F.conv2d(x, kernel, stride = self.stride)\n",
    "        return self.a * x + self.b \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetOriginal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding = 2)\n",
    "        self.subsampling1 = SubSampling(2 , 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.subsampling2 = SubSampling(2,2)\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.f1 = nn.Linear(120, 84)\n",
    "        self.f2 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        C1 = self.conv1(x)\n",
    "        S2 = F.relu(self.subsampling1(C1))\n",
    "        C3 = self.conv2(S2)\n",
    "        S4 = F.relu(self.subsampling2(C3))\n",
    "        C5 = F.relu(self.conv3(S4).squeeze())\n",
    "        F6 = F.relu(self.f1(C5))\n",
    "        return self.f2(F6)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNetOriginal().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(lenet.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lambda e: 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "    accumulated_accuracy = []\n",
    "    for batch, truth in test_dataloader:\n",
    "        weighted_rate = (lenet(batch).argmax(dim = 1) == truth).sum().cpu().numpy()\n",
    "        accumulated_accuracy.append(weighted_rate)\n",
    "    return sum(accumulated_accuracy)/bs/len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba71e41172de4da9b0d9eb2b3a60209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09888\n",
      "0.11342\n",
      "0.8363400000000001\n",
      "0.90716\n",
      "0.9264199999999999\n",
      "0.9347000000000001\n",
      "0.94496\n",
      "0.95078\n",
      "0.9476\n",
      "0.95462\n",
      "0.9557599999999999\n",
      "0.95128\n",
      "0.9597\n",
      "0.95378\n",
      "0.96236\n",
      "0.96402\n",
      "0.96716\n",
      "0.95814\n",
      "0.9691000000000001\n",
      "0.9694400000000001\n",
      "0.96858\n",
      "0.9653999999999999\n",
      "0.9722000000000001\n",
      "0.9706\n",
      "0.97176\n",
      "0.9749\n",
      "0.97276\n",
      "0.97536\n",
      "0.97282\n",
      "0.97474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs = 30\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    temp = get_accuracy()\n",
    "    accuracy.append(temp)\n",
    "    print(temp)\n",
    "    for batch, preds in train_dataloader:\n",
    "        y_pred = lenet(batch)\n",
    "        \n",
    "        l = loss(y_pred, preds)\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09888,\n",
       " 0.11342,\n",
       " 0.8363400000000001,\n",
       " 0.90716,\n",
       " 0.9264199999999999,\n",
       " 0.9347000000000001,\n",
       " 0.94496,\n",
       " 0.95078,\n",
       " 0.9476,\n",
       " 0.95462,\n",
       " 0.9557599999999999,\n",
       " 0.95128,\n",
       " 0.9597,\n",
       " 0.95378,\n",
       " 0.96236,\n",
       " 0.96402,\n",
       " 0.96716,\n",
       " 0.95814,\n",
       " 0.9691000000000001,\n",
       " 0.9694400000000001,\n",
       " 0.96858,\n",
       " 0.9653999999999999,\n",
       " 0.9722000000000001,\n",
       " 0.9706,\n",
       " 0.97176,\n",
       " 0.9749,\n",
       " 0.97276,\n",
       " 0.97536,\n",
       " 0.97282,\n",
       " 0.97474]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are stuck in a local minimum :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo=next(iter(train_dataloader))[0].type(torch.float32).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[[0,0],[0,0]] for _ in range(5)]).unsqueeze(1).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[[1,1],[1,1]] for _ in range(5)]).unsqueeze(1).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 5, 27, 27])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(foo, kernel).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor(0.8417, device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor(1.0038, device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(lenet.modules())[2].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002AB911543C8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.subsampling1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-f3b1bea1571b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'data'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"LeNet5_architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll change some parts like subsampling to MaxPool and Euclidean distance to Cross Entropy Loss. Also we used ReLU instead of a sigmoid activation. These changes are what I call \"modern\" approaches because through the year these have been shown to outperform the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(root = \"../data\", download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrainingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, mean, std):\n",
    "        super().__init__()\n",
    "        train = data.reshape((-1,1,28,28))\n",
    "        flat = train.flatten().to(torch.float32)\n",
    "\n",
    "        self.train = ((train - mean)/ std).to(device)\n",
    "        self.label = targets.to(torch.long).to(device)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.train[i], self.label[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_datasets():\n",
    "    #we have to use the training mean on the test set\n",
    "    train = mnist.data[:50000].reshape((-1,1,28,28))\n",
    "    flat = train.flatten().to(torch.float32)\n",
    "    mean = flat.mean()\n",
    "    std = flat.std()\n",
    "    \n",
    "    return MNISTTrainingDataset(mnist.data[:50000], mnist.targets[:50000], mean,std),\\\n",
    "        MNISTTrainingDataset(mnist.data[50000:], mnist.targets[50000:], mean, std)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = train_test_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size = bs, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size = bs, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetModern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding = 2)\n",
    "        self.subsampling1 = nn.MaxPool2d(2 , 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.subsampling2 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.f1 = nn.Linear(120, 84)\n",
    "        self.f2 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        C1 = self.conv1(x)\n",
    "        S2 = F.relu(self.subsampling1(C1))\n",
    "        C3 = self.conv2(S2)\n",
    "        S4 = F.relu(self.subsampling2(C3))\n",
    "        C5 = F.relu(self.conv3(S4).squeeze())\n",
    "        F6 = F.relu(self.f1(C5))\n",
    "        return self.f2(F6)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_modern = LeNetModern().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(lenet_modern.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lambda e: 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "    accumulated_accuracy = []\n",
    "    for batch, truth in test_dataloader:\n",
    "        weighted_rate = (lenet_modern(batch).argmax(dim = 1) == truth).sum().cpu().numpy()\n",
    "        accumulated_accuracy.append(weighted_rate)\n",
    "    return sum(accumulated_accuracy)/bs/len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5d07241ce44dbe981337c7bae140ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991599999999999\n",
      "0.9994\n",
      "0.9995\n",
      "0.9986\n",
      "0.9994400000000001\n",
      "0.99836\n",
      "0.9990800000000001\n",
      "0.99972\n",
      "0.9997999999999999\n",
      "0.99982\n",
      "0.9998400000000001\n",
      "0.99982\n",
      "0.99986\n",
      "0.99994\n",
      "0.99998\n",
      "0.99994\n",
      "0.9999600000000001\n",
      "0.9999\n",
      "0.99988\n",
      "0.99994\n",
      "0.99998\n",
      "0.99964\n",
      "0.9999600000000001\n",
      "0.99998\n",
      "0.9997999999999999\n",
      "1.0\n",
      "0.99988\n",
      "1.0\n",
      "0.99994\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs = 30\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    temp = get_accuracy()\n",
    "    accuracy.append(temp)\n",
    "    print(temp)\n",
    "    for batch, preds in train_dataloader:\n",
    "        y_pred = lenet_modern(batch)\n",
    "        \n",
    "        l = loss(y_pred, preds)\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10804000000000001,\n",
       " 0.9332999999999999,\n",
       " 0.9632200000000001,\n",
       " 0.97072,\n",
       " 0.98066,\n",
       " 0.98262,\n",
       " 0.9855,\n",
       " 0.988,\n",
       " 0.9885,\n",
       " 0.9916799999999999,\n",
       " 0.99222,\n",
       " 0.99142,\n",
       " 0.992,\n",
       " 0.9940399999999999,\n",
       " 0.99482,\n",
       " 0.9946200000000001,\n",
       " 0.9947,\n",
       " 0.9950800000000001,\n",
       " 0.99414,\n",
       " 0.99598,\n",
       " 0.99454,\n",
       " 0.9969199999999999,\n",
       " 0.9979199999999999,\n",
       " 0.99774,\n",
       " 0.996,\n",
       " 0.9986,\n",
       " 0.99822,\n",
       " 0.998,\n",
       " 0.99862,\n",
       " 0.99878]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f4e85c4deb2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfoo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "foo=next(iter(dataloader))[0].type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[[0,0],[0,0]] for _ in range(5)]).unsqueeze(1).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(foo, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
       "\n",
       "\n",
       "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          ...,\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
       "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 16, 5, 5])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for parameter in lenet_modern.parameters():\n",
    "    print(parameter.data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
